# pylint: disable=C0103
"""
Finished moving case management information to the backend by changing existing tables

Changed tables:
case
case_event

New tables:
case_type_default_event
case_metadata

Revision ID: 1a712d1436eb
Revises: 0dc00a57046c
Create Date: 2019-07-12 16:54:52.036167

"""
import os

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from sqlalchemy.dialects.postgresql import ENUM

# revision identifiers, used by Alembic.
revision = '1a712d1436eb'
down_revision = '0dc00a57046c'
branch_labels = None
depends_on = None


event_type_enum = ENUM(
    'GLOBAL',
    'USER',
    'STATUS_CHANGE',
    'METADATA_CHANGE',
    name='event_type_enum',
    create_type=False,
)


# pylint: disable=E1101
def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    # Add the enum
    event_type_enum.create(op.get_bind(), checkfirst=True)

    # This table is not currently used anywhere
    op.drop_table('case_event')

    with op.batch_alter_table('case', schema=None) as batch_op:
        # Change the id column from string to integer
        batch_op.drop_column('id')
        batch_op.add_column(
            sa.Column(
                'id', sa.Integer(), nullable=False, autoincrement=True, primary_key=True
            )
        )
        # Needs both the primary_key flag and explicitly creating it
        batch_op.create_primary_key('case_pkey', ['id'])

        batch_op.add_column(sa.Column('druid_dimension_id', sa.Text(), nullable=True))
        batch_op.add_column(
            sa.Column('alert_notification_id', sa.Integer(), nullable=True)
        )
        batch_op.add_column(
            sa.Column('case_status_type_id', sa.Integer(), nullable=True)
        )
        batch_op.add_column(sa.Column('case_type_id', sa.Integer(), nullable=True))
        batch_op.add_column(
            sa.Column('spec', postgresql.JSONB(astext_type=sa.Text()), nullable=True)
        )

        batch_op.create_foreign_key(
            'valid_case_type', 'case_type', ['case_type_id'], ['id'], ondelete='CASCADE'
        )
        batch_op.create_foreign_key(
            'valid_alert_notification',
            'alert_notifications',
            ['alert_notification_id'],
            ['id'],
            ondelete='CASCADE',
        )
        batch_op.create_foreign_key(
            'valid_status',
            'case_status_type',
            ['case_status_type_id'],
            ['id'],
            onupdate='CASCADE',
            ondelete='RESTRICT',
        )
        batch_op.create_unique_constraint(
            'unique_druid_dimension_id', ['druid_dimension_id']
        )
        batch_op.create_unique_constraint(
            'unique_alert_notification_id', ['alert_notification_id']
        )

    op.create_table(
        'case_event',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.Text(), nullable=False),
        sa.Column('created', sa.DateTime(), nullable=False),
        sa.Column('type', event_type_enum, nullable=False),
        sa.Column('description', sa.Text(), nullable=True),
        sa.Column(
            'additional_info', postgresql.JSONB(astext_type=sa.Text()), nullable=False
        ),
        sa.Column('case_id', sa.Integer(), nullable=True),
        sa.ForeignKeyConstraint(
            ['case_id'], ['case.id'], name='valid_case', ondelete='CASCADE'
        ),
        sa.PrimaryKeyConstraint('id'),
    )
    op.create_table(
        'case_type_default_event',
        sa.Column('case_event_id', sa.Integer(), nullable=False),
        sa.Column('case_type_id', sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ['case_event_id'],
            ['case_event.id'],
            name='valid_case_event',
            ondelete='CASCADE',
        ),
        sa.ForeignKeyConstraint(
            ['case_type_id'],
            ['case_type.id'],
            name='valid_case_type',
            ondelete='CASCADE',
        ),
        sa.PrimaryKeyConstraint('case_event_id', 'case_type_id'),
    )
    op.create_table(
        'case_metadata',
        sa.Column('case_id', sa.Integer(), nullable=False),
        sa.Column('case_metadata_type_id', sa.Integer(), nullable=False),
        sa.Column('value', sa.Text(), nullable=False),
        sa.ForeignKeyConstraint(
            ['case_id'], ['case.id'], name='valid_case', ondelete='CASCADE'
        ),
        sa.ForeignKeyConstraint(
            ['case_metadata_type_id'],
            ['case_metadata_type.id'],
            name='valid_case_metadata_type',
            ondelete='CASCADE',
        ),
        sa.PrimaryKeyConstraint('case_id', 'case_metadata_type_id'),
    )

    # HACK(toshi): Bad practice, but only upvert mz data
    if os.environ['ZEN_ENV'] == 'mz' and not os.getenv('MZ_COVID'):
        from web.server.migrations.seed_scripts.seed_1a712d1436eb import upvert_data

        upvert_data(op)

    with op.batch_alter_table('case', schema=None) as batch_op:
        batch_op.alter_column(
            'case_status_type_id', existing_nullable=True, nullable=False
        )
        batch_op.alter_column('case_type_id', existing_nullable=True, nullable=False)

        batch_op.drop_column('type')
        batch_op.drop_column('name')
        batch_op.drop_column('case_spec')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('case', schema=None) as batch_op:
        batch_op.add_column(sa.Column('name', sa.String(), nullable=True))
        batch_op.add_column(sa.Column('type', sa.String(), nullable=True))
        batch_op.add_column(
            sa.Column(
                'case_spec', postgresql.JSONB(astext_type=sa.Text()), nullable=True
            )
        )

        batch_op.alter_column(
            'case_status_type_id', existing_nullable=False, nullable=True
        )
        batch_op.alter_column('case_type_id', existing_nullable=False, nullable=True)

    # HACK(toshi): Bad practice, but only downvert mz data
    is_mz = os.environ['ZEN_ENV'] == 'mz'
    if is_mz and not os.getenv('MZ_COVID'):
        from web.server.migrations.seed_scripts.seed_1a712d1436eb import downvert_data

        downvert_data(op)

    op.drop_table('case_metadata')
    op.drop_table('case_type_default_event')
    op.drop_table('case_event')

    op.alter_column(
        'case', 'id', existing_type=sa.Integer(), type_=sa.String(), server_default=None
    )

    if is_mz and not os.getenv('MZ_COVID'):
        from web.server.migrations.seed_scripts.seed_1a712d1436eb import recreate_id

        recreate_id(op)

    with op.batch_alter_table('case', schema=None) as batch_op:
        batch_op.alter_column('case_spec', existing_nullable=True, nullable=False)

        batch_op.drop_constraint('unique_alert_notification_id', type_='unique')
        batch_op.drop_constraint('unique_druid_dimension_id', type_='unique')
        batch_op.drop_constraint('valid_status', type_='foreignkey')
        batch_op.drop_constraint('valid_alert_notification', type_='foreignkey')
        batch_op.drop_constraint('valid_case_type', type_='foreignkey')
        batch_op.drop_column('spec')
        batch_op.drop_column('case_type_id')
        batch_op.drop_column('case_status_type_id')
        batch_op.drop_column('alert_notification_id')
        batch_op.drop_column('druid_dimension_id')

    op.create_table(
        'case_event',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(), nullable=True),
        sa.Column('date', sa.String(), nullable=True),
        sa.Column('type', sa.Date(), nullable=True),
        sa.PrimaryKeyConstraint('id'),
    )

    # Drop the enum
    event_type_enum.drop(op.get_bind(), checkfirst=True)
    # ### end Alembic commands ###
