version: "3.7"

x-logging:
  &default-logging
  driver: "json-file"
  options:
    max-size: 10m
    max-file: "10"

services:
  postgres:
    # Postgres included for ease of testing. The configuration for postgres
    # included here is not production ready!
    # For production, postgres should be configured to be highly available
    # and should have appropriate backup and recovery procedures in place.
    profiles:
      - demonstration
    image: postgres:13.7-alpine
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - pgdata-volume:/var/lib/postgresql/data
    # If resource management is required - see:
    # https://docs.docker.com/compose/compose-file/deploy/#resources
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '0.50'
    #       memory: 50M
    #       pids: 1
    #     reservations:
    #       cpus: '0.25'
    #       memory: 20M
  minio:
    # Minio included for ease of testing. The configuration for minio
    # included here is not production ready!
    # For production, minio should be configured to be highly available
    # and should have appropriate backup and recovery procedures in place.
    profiles:
      - demonstration
    image: minio/minio
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    hostname: minio
    ports:
      # web-renderer uses 9000, so we bump up to 9001
      # minio API runs on 9000
      - 9000:9000
      - 9090:9090
    volumes:
      - minio-data-volume:/data
    command: [ "server", "/data", "--console-address", ":9090" ]
  nginx:
    image: nginxproxy/nginx-proxy:alpine
    restart: always
    pull_policy: always
    ports:
      - 80:80
      - 443:443
    labels:
      com.github.jrcs.letsencrypt_nginx_proxy_companion.nginx_proxy: ""
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock:ro
      # Bind the SSL certificate path from the host system to the
      # directory the nginx container uses for all certs.
      - /etc/ssl/certs:/etc/nginx/certs:ro
      - nginx_vhost:/etc/nginx/vhost.d
      - nginx_html:/usr/share/nginx/html
      # Include Zenysis static assets and serve them directly from nginx.
      - ${OUTPUT_PATH}/zenysis_static:/usr/share/nginx/html/zenysis_static:ro
      # Set a custom vhost default configuration that includes compression and caching.
      - ${NGINX_DEFAULT_VHOST_CONFIG}:/etc/nginx/vhost.d/default:ro
    logging: *default-logging

  nginx-letsencrypt-companion:
    image: nginxproxy/acme-companion:latest
    restart: always
    pull_policy: always
    environment:
      - DHPARAM_BITS=4096
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # These are the same volumes used by the nginx image.
      # This is on purpose since the letsencrypt companion container works
      # with the nginx container collaboratively to generate SSL certs.
      - /etc/ssl/certs:/etc/nginx/certs:rw
      - nginx_vhost:/etc/nginx/vhost.d
      - nginx_html:/usr/share/nginx/html
      - nginx-acme:/etc/acme.sh
    logging: *default-logging

  web:
    # build:
    #   dockerfile: Dockerfile
    #   context: ../
    platform: linux/amd64
    image: ${DOCKER_NAMESPACE}/${DOCKER_IMAGE:-harmony-web}:${DOCKER_TAG}
    restart: always
    pull_policy: always
    ports:
      - 5000:5000
    environment:
      - ZEN_ENV=${ZEN_WEB_ENV}
      - DONT_SYNC_SOURCEMAPS=true
      - DATABASE_URL=${POSTGRES_DB_URI}
      - HSTS=off
      - SSL_POLICY=Mozilla-Modern
      - VIRTUAL_HOST=${ZEN_WEB_HOST}
      - LETSENCRYPT_HOST=${ZEN_WEB_HOST}
      - LETSENCRYPT_EMAIL=${ZEN_WEB_EMAIL}
    volumes:
      - ${OUTPUT_PATH}:/data/output
      - ${OUTPUT_PATH}/logs:/logs
      - ${INSTANCE_CONFIG}:/zenysis/instance_config.json
      - ${GLOBAL_CONFIG}:/zenysis/global_config.py
      - ${UPLOADS_DIR}:/zenysis/uploads
    command: [ "/zenysis/docker/entrypoint_web.sh" ]
    logging: *default-logging

  worker:
    platform: linux/amd64
    image: ${DOCKER_NAMESPACE}/${DOCKER_IMAGE:-harmony-web}:${DOCKER_TAG}
    restart: always
    pull_policy: always
    ports:
      - 61234:61234
    environment:
      - ZEN_ENV=${ZEN_WEB_ENV}
      - ZEN_LOG_CFG=/zenysis/log/log.prod-stackdriver.cfg
      - BROKER_URL=redis://redis:6379/0
    volumes:
      - ${OUTPUT_PATH}/logs:/logs
      - ${INSTANCE_CONFIG}:/zenysis/instance_config.json
      - ${GLOBAL_CONFIG}:/zenysis/global_config.py
    command:
      [
        "celery",
        "-A",
        "web.background_worker.celery",
        "worker",
        "--beat",
        "--loglevel=INFO"
      ]
    logging: *default-logging

  web-renderer:
    platform: linux/amd64
    image: zengineering/url-to-pdf-api:latest
    restart: always
    pull_policy: always
    ports:
      - 9001:9000
    environment:
      - ALLOW_HTTP=true
      - PORT=9000

  redis:
    image: redis:latest
    restart: always
    pull_policy: always
    ports:
      - 6379:6379

  hasura:
    image: hasura/graphql-engine:latest.cli-migrations-v2
    restart: always
    pull_policy: always
    ports:
      - 8080:8080
    environment:
      - HASURA_GRAPHQL_ENABLE_TELEMETRY=false
      - HASURA_GRAPHQL_MIGRATIONS_SERVER_TIMEOUT=500
      - HASURA_GRAPHQL_DATABASE_URL=${GRAPHQL_DATABASE_URL}
    volumes:
      - ${OUTPUT_PATH}/logs:/logs

volumes:
  # Let's Encrypt container needs to configure the vhosts during
  # cert issuing.
  nginx_vhost: # This html directory is only used to write let's encrypt challenge

  # files during the cert issuing process.
  nginx_html: # The acme.sh diretory stores the generated certificate state

  # This prevents re-issuing of the certificate if the container is restarted/re-created
  # It should only issue if there is no certificate or it is close to expiry.
  # Read more here: https://github.com/nginx-proxy/acme-companion/issues/510
  nginx-acme:

  # This volume is used to store the postgres data.
  pgdata-volume:
    # We may want to point this to a specific location on the host system,
    # in that case - uncomment the following lines and set the PG_DATA_VOLUME
    # driver: local
    # driver_opts:
    #   type: none
    #   o: bind
    #   device: "${PG_DATA_VOLUME:-/var/lib/postgresql/data}"

  # This volume is used to store the minio data.
  minio-data-volume:
    # We may want to point this to a specific location on the host system,
    # in that case - uncomment the following lines and set the MINIO_DATA_VOLUME
    # driver: local
    # driver_opts:
    #   type: none
    #   o: bind
    #   device: "${MINIO_DATA_VOLUME:-/var/lib/minio/data}"

